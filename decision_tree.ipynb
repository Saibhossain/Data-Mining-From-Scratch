{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/saibhossain/decision-tree?scriptVersionId=288842486\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"###  What Is a Decision Tree?\n- Used for **classification** and **regression**.\n- Structure:\n  - **Internal nodes**: Test on a feature (`Age ≤ 30?`)\n  - **Branches**: Outcome of the test\n  - **Leaf nodes**: Final prediction (class label or numeric value)","metadata":{}},{"cell_type":"markdown","source":"###  Decision Trees: Summary\n\nA **decision tree** is a supervised learning model that makes predictions by recursively splitting the data based on feature values, forming a tree-like structure of interpretable **if–else rules**.","metadata":{}},{"cell_type":"markdown","source":"###  How It Works\n1. Start with all data at the **root**.\n2. **Select the best feature** to split the data (based on impurity reduction).\n3. **Split** the dataset into subsets.\n4. **Repeat recursively** for each subset.\n5. Stop when a **stopping condition** is met (e.g., max depth, min samples per leaf).\n6. Assign the **majority class** (classification) or **mean value** (regression) at leaf nodes.","metadata":{}},{"cell_type":"markdown","source":"### Split Criteria (Minimizing Impurity)\n\n| Algorithm | Criterion | Formula |\n|----------|----------|--------|\n| **CART** | **Gini Index** | $ \\text{Gini} = 1 - \\sum p_i^2 $ |\n| **ID3 / C4.5** | **Entropy** | $ \\text{Entropy} = -\\sum p_i \\log_2 p_i $ |\n| | **Information Gain** | $ \\text{IG} = \\text{Entropy}_{\\text{parent}} - \\sum \\text{Entropy}_{\\text{children}} $ |\n| **Regression Trees** | **MSE** | $ \\text{MSE} = \\frac{1}{n} \\sum (y_i - \\hat{y})^2 $ |\n","metadata":{}},{"cell_type":"markdown","source":"\n###  Simple Example\n\n**Rule-based view**:\n```python\nIf Weather == \"Sunny\":\n    If Humidity > 75 → \"No\"\n    Else → \"Yes\"\nElse → \"Yes\"\n```","metadata":{}},{"cell_type":"markdown","source":"### Tree visualization:\n\n            Weather\n            /     \\\n        Sunny    Rainy\n          |\n       Humidity\n        /    \\\n      High   Low\n       No     Yes","metadata":{}},{"cell_type":"markdown","source":"### Advantages\n* Easy to understand and interpret\n* Handles numerical and categorical data\n* Requires little data preprocessing\n* Mimics human decision-making\n\n\n\n### Disadvantages\n* Prone to overfitting\n* Sensitive to small data changes\n* Lower accuracy than ensembles (Random Forest, XGBoost)","metadata":{}},{"cell_type":"markdown","source":"### Numerical Dataset\nWe predict Pass (1) / Fail (0) based on Study Hours and Attendance (%)","metadata":{}},{"cell_type":"markdown","source":"| Study Hours | Attendance | Result |\n| ----------- | ---------- | ------ |\n| 2           | 60         | 0      |\n| 4           | 70         | 0      |\n| 6           | 75         | 1      |\n| 8           | 85         | 1      |\n| 10          | 95         | 1      |\n","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# Features: [Study Hours, Attendance]\nX = [\n    [2, 60],\n    [4, 70],\n    [6, 75],\n    [8, 85],\n    [10, 95]\n]\n\ny = [0, 0, 1, 1, 1] # Labels: 0 = Fail, 1 = Pass\n\nmodel = DecisionTreeClassifier(criterion=\"gini\")\nmodel.fit(X, y)\n\nprediction = model.predict([[5, 72]])\nprint(\"Prediction (0=Fail, 1=Pass):\", prediction[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}